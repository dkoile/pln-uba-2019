{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab2 import *\n",
    "train, dev, X_test = load_datasets_unlabeled_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(963, 107, 500)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = train\n",
    "X_dev, y_dev = dev\n",
    "len(X_train), len(X_dev), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "accuracy\t0.86\tmacro f1\t0.86\n",
      "accuracy\t0.83\tmacro f1\t0.83\n",
      "<class 'sklearn.naive_bayes.MultinomialNB'>\n",
      "accuracy\t0.99\tmacro f1\t0.99\n",
      "accuracy\t0.84\tmacro f1\t0.84\n",
      "<class 'sklearn.tree.tree.DecisionTreeClassifier'>\n",
      "accuracy\t1.00\tmacro f1\t1.00\n",
      "accuracy\t0.70\tmacro f1\t0.70\n",
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/.virtualenvs/pln/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.99\tmacro f1\t0.99\n",
      "accuracy\t0.88\tmacro f1\t0.88\n",
      "<class 'sklearn.svm.classes.LinearSVC'>\n",
      "accuracy\t1.00\tmacro f1\t1.00\n",
      "accuracy\t0.87\tmacro f1\t0.87\n",
      "<class 'sklearn.svm.classes.SVC'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/.virtualenvs/pln/lib/python3.5/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/daniel/.virtualenvs/pln/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.50\tmacro f1\t0.33\n",
      "accuracy\t0.50\tmacro f1\t0.33\n",
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/.virtualenvs/pln/lib/python3.5/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.99\tmacro f1\t0.99\n",
      "accuracy\t0.75\tmacro f1\t0.74\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from tagging.fasttext2 import FasttextDictVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from util import print_short_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "\n",
    "#probando distintos clasificadores\n",
    "clfs = [\n",
    "    KNeighborsClassifier(),\n",
    "    MultinomialNB(),\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    LogisticRegression(random_state=0),\n",
    "    LinearSVC(random_state=0),\n",
    "    SVC(random_state=0),\n",
    "    RandomForestClassifier(random_state=0),\n",
    "]\n",
    "\n",
    "#probar vectorizadores\n",
    "vect = TfidfVectorizer(binary=True) #solo mejora el logistic regression\n",
    "#vect = CountVectorizer(binary=True)\n",
    "\n",
    "for clf in clfs:\n",
    "    print(str(clf.__class__))\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', vect),\n",
    "        ('clf', clf),\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    print_short_eval(pipeline, X_train, y_train)\n",
    "    print_short_eval(pipeline, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.91\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.88      0.94      0.91        54\n",
      "         pos       0.94      0.87      0.90        53\n",
      "\n",
      "    accuracy                           0.91       107\n",
      "   macro avg       0.91      0.91      0.91       107\n",
      "weighted avg       0.91      0.91      0.91       107\n",
      "\n",
      "[[51  3]\n",
      " [ 7 46]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/.virtualenvs/pln/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from util import print_eval\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(\n",
    "        binary=True,\n",
    "        min_df=5,\n",
    "        max_df=0.95,\n",
    "        ngram_range=(1, 3),\n",
    "        #stop_words='english',\n",
    "    )),\n",
    "    ('clf', LogisticRegression(random_state=0)),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "print_eval(pipeline, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid search\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "param_grid = {\n",
    "    'vect__binary': [True],\n",
    "    #'vect__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5)],\n",
    "    #'vect__min_df': [1, 3, 5, 7],\n",
    "    #'vect__max_df': [0.95, 0.9, 0.7],\n",
    "    #segunda vuelta\n",
    "    'vect__ngram_range': [(1, 3)],\n",
    "    'vect__min_df': [ 5],\n",
    "    'vect__max_df': [0.95],\n",
    "\n",
    "    #mismos resultados\n",
    "    'clf__alpha': [1.0,5.0,10.0,11.5,11.8,11.9,11.95,12.0,12.05,12.1,12.3,12.4]\n",
    "    #'clf__alpha': [10.0,11.0,12.0,13.0]\n",
    "}\n",
    "\n",
    "params_list = list(ParameterGrid(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.89\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.92      0.85      0.88        54\n",
      "         pos       0.86      0.92      0.89        53\n",
      "\n",
      "    accuracy                           0.89       107\n",
      "   macro avg       0.89      0.89      0.89       107\n",
      "weighted avg       0.89      0.89      0.89       107\n",
      "\n",
      "[[46  8]\n",
      " [ 4 49]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from util import print_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(\n",
    "        binary=True,\n",
    "        min_df=5,\n",
    "        max_df=0.95,\n",
    "        ngram_range=(1, 3),\n",
    "        #stop_words='english',\n",
    "    )),\n",
    "    ('clf', MultinomialNB(alpha=12.0,fit_prior=True)),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "print_eval(pipeline, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from util import eval\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "results = []\n",
    "for params in params_list:\n",
    "    # TODO: add progress bar!\n",
    "    pipeline.set_params(**params)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    result = eval(pipeline, X_dev, y_dev)\n",
    "    \n",
    "    results.append({\n",
    "        **result,\n",
    "        **params,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>clf__alpha</th>\n",
       "      <th>f1</th>\n",
       "      <th>vect__binary</th>\n",
       "      <th>vect__max_df</th>\n",
       "      <th>vect__min_df</th>\n",
       "      <th>vect__ngram_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.887850</td>\n",
       "      <td>11.80</td>\n",
       "      <td>0.887762</td>\n",
       "      <td>True</td>\n",
       "      <td>0.95</td>\n",
       "      <td>5</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.887850</td>\n",
       "      <td>11.90</td>\n",
       "      <td>0.887762</td>\n",
       "      <td>True</td>\n",
       "      <td>0.95</td>\n",
       "      <td>5</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.887850</td>\n",
       "      <td>11.95</td>\n",
       "      <td>0.887762</td>\n",
       "      <td>True</td>\n",
       "      <td>0.95</td>\n",
       "      <td>5</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.887850</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.887762</td>\n",
       "      <td>True</td>\n",
       "      <td>0.95</td>\n",
       "      <td>5</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.887850</td>\n",
       "      <td>12.05</td>\n",
       "      <td>0.887762</td>\n",
       "      <td>True</td>\n",
       "      <td>0.95</td>\n",
       "      <td>5</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.887850</td>\n",
       "      <td>12.10</td>\n",
       "      <td>0.887762</td>\n",
       "      <td>True</td>\n",
       "      <td>0.95</td>\n",
       "      <td>5</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.887850</td>\n",
       "      <td>12.30</td>\n",
       "      <td>0.887762</td>\n",
       "      <td>True</td>\n",
       "      <td>0.95</td>\n",
       "      <td>5</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.878505</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.878462</td>\n",
       "      <td>True</td>\n",
       "      <td>0.95</td>\n",
       "      <td>5</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.878505</td>\n",
       "      <td>11.50</td>\n",
       "      <td>0.878462</td>\n",
       "      <td>True</td>\n",
       "      <td>0.95</td>\n",
       "      <td>5</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.878505</td>\n",
       "      <td>12.40</td>\n",
       "      <td>0.878335</td>\n",
       "      <td>True</td>\n",
       "      <td>0.95</td>\n",
       "      <td>5</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         acc  clf__alpha        f1  vect__binary  vect__max_df  vect__min_df  \\\n",
       "4   0.887850       11.80  0.887762          True          0.95             5   \n",
       "5   0.887850       11.90  0.887762          True          0.95             5   \n",
       "6   0.887850       11.95  0.887762          True          0.95             5   \n",
       "7   0.887850       12.00  0.887762          True          0.95             5   \n",
       "8   0.887850       12.05  0.887762          True          0.95             5   \n",
       "9   0.887850       12.10  0.887762          True          0.95             5   \n",
       "10  0.887850       12.30  0.887762          True          0.95             5   \n",
       "2   0.878505       10.00  0.878462          True          0.95             5   \n",
       "3   0.878505       11.50  0.878462          True          0.95             5   \n",
       "11  0.878505       12.40  0.878335          True          0.95             5   \n",
       "\n",
       "   vect__ngram_range  \n",
       "4             (1, 3)  \n",
       "5             (1, 3)  \n",
       "6             (1, 3)  \n",
       "7             (1, 3)  \n",
       "8             (1, 3)  \n",
       "9             (1, 3)  \n",
       "10            (1, 3)  \n",
       "2             (1, 3)  \n",
       "3             (1, 3)  \n",
       "11            (1, 3)  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.sort_values(['acc', 'f1'], ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'subjclueslen1-HLTEMNLP05.tff'\n",
    "f = open(filename)\n",
    "lines = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for line in lines:\n",
    "    sline = line.split()\n",
    "    dline = dict([token.split('=') for token in sline if '=' in token])\n",
    "    word = dline['word1']\n",
    "    pol = dline['priorpolarity']\n",
    "    if pol not in {'both', 'neutral'}:\n",
    "        if pol in {'negative', 'weakneg'}:\n",
    "            pol = 'NEG'\n",
    "        else:\n",
    "            pol = 'POS'\n",
    "        words.append((word, pol))\n",
    "\n",
    "word_dict = dict(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkn = CountVectorizer().build_tokenizer()\n",
    "def my_tkn(s):\n",
    "    tokens = tkn(s)\n",
    "    return [word_dict.get(token, token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=<function my_tkn at 0x7f0c605b5950>,\n",
       "                vocabulary=['POS', 'NEG'])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(vocabulary=['POS', 'NEG'], tokenizer=my_tkn)\n",
    "vect.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.88\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.92      0.83      0.87        54\n",
      "         pos       0.84      0.92      0.88        53\n",
      "\n",
      "    accuracy                           0.88       107\n",
      "   macro avg       0.88      0.88      0.88       107\n",
      "weighted avg       0.88      0.88      0.88       107\n",
      "\n",
      "[[45  9]\n",
      " [ 4 49]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from util import print_eval\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', FeatureUnion([\n",
    "        ('bow', CountVectorizer(       \n",
    "        binary=True,\n",
    "        min_df=5,\n",
    "        max_df=0.95,\n",
    "        ngram_range=(1, 3),)),\n",
    "        ('pol', \n",
    "             Pipeline([\n",
    "                ('pol', CountVectorizer(vocabulary=['POS', 'NEG'], tokenizer=my_tkn)),\n",
    "                ('scl', StandardScaler(with_mean=False)),\n",
    "            ])\n",
    "        )\n",
    "    ])),\n",
    "    ('clf', MultinomialNB(alpha=12.0,fit_prior=True)),\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "print_eval(pipeline, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results('my_classifierMNBtknHiper.csv', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
